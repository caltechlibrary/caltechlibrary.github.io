<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <title>Caltech Library's DLD Labs</title>
    <link rel="stylesheet" href="/css/site.css">
    <link rel="alternate" type="application/rss+xml" title="Caltech Library, Digital Library Development posts" href="/rss.xml">
    <script type="module" src="https://caltechlibrary.github.io/CL-web-components/src/footer-global.js"></script>
</head>
<body>
<header>
<a href="https://library.caltech.edu"><img src="/assets/liblogo.gif" alt="Caltech Library logo"></a>
</header>
<nav>
<ul>
  <li><a href="/">DLD Labs</a></li>
  <li><a href="https://library.caltech.edu/library/home">Caltech Library</a></li>
  <li><a href="https://library.caltech.edu/archives/home">Caltech Archives</a></li>
  <li><a href="https://feeds.library.caltech.edu">Library Feeds</a></li>
  <li><a href="https://github.com/caltechlibrary/">DLD @ GitHub</a></li>
  <li>&nbsp;</li>
  <li><a href="/search.html">Site Search</a></li>
</ul>
</nav>

<section>
<h1 id="language-models-and-fielded-search">Language models and
“fielded” search</h1>
<p>By R. S. Doiel, 2025-04-10</p>
<p>This an interesting use of an LLM, it means that the old “advanced
search” UI or fielded search UI can be made to feel like a single box
search,
&lt;https://simonwillison.net/2025/Apr/9/an-llm-query-understanding-service/
&gt;. From Simon Willison’s Weblog,</p>
<blockquote>
<p>“Many times, even a small open source LLM will be able to turn a
search query into reasonable structure at relatively low cost.”</p>
</blockquote>
<p>So does this mean the huge Solar/OpenSearch indexes aren’t needed?
Probably not but it does mean that we can build much more effective
search and retrieval systems before requiring a full text search engine.
Running an Ollama instance with an appropriate frugal model is almost
trivial.</p>
</section>

<footer-global></footer-global>
</body>
</html>
